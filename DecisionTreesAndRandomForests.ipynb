{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTreesAndRandomForests.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "1f8d80d535cfd832283e4e3a1095d2ce45fe6627336684f2622a1965babb2f1c"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0_wToNFHMN3"
      },
      "source": [
        "# **Decision Trees**\n",
        "\n",
        "The Wisconsin Breast Cancer Dataset(WBCD) can be found here(https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data)\n",
        "\n",
        "This dataset describes the characteristics of the cell nuclei of various patients with and without breast cancer. The task is to classify a decision tree to predict if a patient has a benign or a malignant tumour based on these features.\n",
        "\n",
        "Attribute Information:\n",
        "```\n",
        "#  Attribute                     Domain\n",
        "   -- -----------------------------------------\n",
        "   1. Sample code number            id number\n",
        "   2. Clump Thickness               1 - 10\n",
        "   3. Uniformity of Cell Size       1 - 10\n",
        "   4. Uniformity of Cell Shape      1 - 10\n",
        "   5. Marginal Adhesion             1 - 10\n",
        "   6. Single Epithelial Cell Size   1 - 10\n",
        "   7. Bare Nuclei                   1 - 10\n",
        "   8. Bland Chromatin               1 - 10\n",
        "   9. Normal Nucleoli               1 - 10\n",
        "  10. Mitoses                       1 - 10\n",
        "  11. Class:                        (2 for benign, 4 for malignant)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYdlWpUVHMOB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a5d775aa-4784-4ef8-b1f4-bf1e297cdb65"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "headers = [\"ID\",\"CT\",\"UCSize\",\"UCShape\",\"MA\",\"SECSize\",\"BN\",\"BC\",\"NN\",\"Mitoses\",\"Diagnosis\"]\n",
        "data = pd.read_csv('breast-cancer-wisconsin.data', na_values='?',    \n",
        "         header=None, index_col=['ID'], names = headers) \n",
        "data = data.reset_index(drop=True)\n",
        "data = data.fillna(0)\n",
        "data.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CT</th>\n",
              "      <th>UCSize</th>\n",
              "      <th>UCShape</th>\n",
              "      <th>MA</th>\n",
              "      <th>SECSize</th>\n",
              "      <th>BN</th>\n",
              "      <th>BC</th>\n",
              "      <th>NN</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.417740</td>\n",
              "      <td>3.134478</td>\n",
              "      <td>3.207439</td>\n",
              "      <td>2.806867</td>\n",
              "      <td>3.216023</td>\n",
              "      <td>3.463519</td>\n",
              "      <td>3.437768</td>\n",
              "      <td>2.866953</td>\n",
              "      <td>1.589413</td>\n",
              "      <td>2.689557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.815741</td>\n",
              "      <td>3.051459</td>\n",
              "      <td>2.971913</td>\n",
              "      <td>2.855379</td>\n",
              "      <td>2.214300</td>\n",
              "      <td>3.640708</td>\n",
              "      <td>2.438364</td>\n",
              "      <td>3.053634</td>\n",
              "      <td>1.715078</td>\n",
              "      <td>0.951273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               CT      UCSize     UCShape  ...          NN     Mitoses   Diagnosis\n",
              "count  699.000000  699.000000  699.000000  ...  699.000000  699.000000  699.000000\n",
              "mean     4.417740    3.134478    3.207439  ...    2.866953    1.589413    2.689557\n",
              "std      2.815741    3.051459    2.971913  ...    3.053634    1.715078    0.951273\n",
              "min      1.000000    1.000000    1.000000  ...    1.000000    1.000000    2.000000\n",
              "25%      2.000000    1.000000    1.000000  ...    1.000000    1.000000    2.000000\n",
              "50%      4.000000    1.000000    1.000000  ...    1.000000    1.000000    2.000000\n",
              "75%      6.000000    5.000000    5.000000  ...    4.000000    1.000000    4.000000\n",
              "max     10.000000   10.000000   10.000000  ...   10.000000   10.000000    4.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_gQq5qrHMOG"
      },
      "source": [
        "1. a) Implement a decision tree (you can use decision tree implementation from existing libraries)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6R3GmzBHMOH"
      },
      "source": [
        "def gini(X_train, y_train, dpt):\n",
        "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=dpt, min_samples_leaf=5)\n",
        "    clf_gini.fit(X_train, y_train)\n",
        "    return clf_gini\n",
        "      \n",
        "def entropy(X_train, y_train, dpt):\n",
        "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth = dpt, min_samples_leaf = 5)\n",
        "    clf_entropy.fit(X_train, y_train)\n",
        "    return clf_entropy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ7N9m_mHMOJ"
      },
      "source": [
        "1. b) Train a decision tree object of the above class on the WBC dataset using misclassification rate, entropy and Gini as the splitting metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHFij6PaHMOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1780d7-0cf3-4d3b-c230-1753eedcfc33"
      },
      "source": [
        "X = data.values[:, 0:9]\n",
        "Y = data.values[:, 9]\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, train_size = 0.7, random_state = 100)\n",
        "usedGini = gini(X_train, y_train, 3)\n",
        "y_gini = usedGini.predict(X_test)\n",
        "usedEntropy = entropy(X_train, y_train, 3)\n",
        "y_entropy = usedEntropy.predict(X_test)\n",
        "print(\"Accuracy using entropy: \", accuracy_score(y_test,y_entropy)*100)\n",
        "print(\"Accuracy using gini: \", accuracy_score(y_test,y_gini)*100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using entropy:  91.9047619047619\n",
            "Accuracy using gini:  93.33333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXEjInvmHMOK"
      },
      "source": [
        "1. c) Report the accuracies in each of the above splitting metrics and give the best result. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49QZvmgNHMOL"
      },
      "source": [
        "Accuracy using entropy:  91.9047619047619\n",
        "Accuracy using gini:  93.33333333333333\n",
        "Using gini gave the best accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz_7nYxPHMON"
      },
      "source": [
        "1. d) Experiment with different approaches to decide when to terminate the tree (number of layers, purity measure, etc). Report and give explanations for all approaches. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLRI0niJHMOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585bb5e5-f426-4127-9e0c-1bf39fb17a88"
      },
      "source": [
        "layers = 10\n",
        "for i in range(1, layers+1):\n",
        "  print(\"depth = \", i)\n",
        "  usedGini = gini(X_train, y_train, i)\n",
        "  y_gini = usedGini.predict(X_test)\n",
        "  usedEntropy = entropy(X_train, y_train, i)\n",
        "  y_entropy = usedEntropy.predict(X_test)\n",
        "  print(\"Accuracy using entropy: \", accuracy_score(y_test,y_entropy)*100)\n",
        "  print(\"Accuracy using gini: \", accuracy_score(y_test,y_gini)*100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth =  1\n",
            "Accuracy using entropy:  89.52380952380953\n",
            "Accuracy using gini:  88.09523809523809\n",
            "depth =  2\n",
            "Accuracy using entropy:  88.57142857142857\n",
            "Accuracy using gini:  92.85714285714286\n",
            "depth =  3\n",
            "Accuracy using entropy:  91.9047619047619\n",
            "Accuracy using gini:  93.33333333333333\n",
            "depth =  4\n",
            "Accuracy using entropy:  93.33333333333333\n",
            "Accuracy using gini:  93.33333333333333\n",
            "depth =  5\n",
            "Accuracy using entropy:  92.85714285714286\n",
            "Accuracy using gini:  93.33333333333333\n",
            "depth =  6\n",
            "Accuracy using entropy:  93.80952380952381\n",
            "Accuracy using gini:  94.28571428571428\n",
            "depth =  7\n",
            "Accuracy using entropy:  93.80952380952381\n",
            "Accuracy using gini:  94.28571428571428\n",
            "depth =  8\n",
            "Accuracy using entropy:  93.80952380952381\n",
            "Accuracy using gini:  94.28571428571428\n",
            "depth =  9\n",
            "Accuracy using entropy:  93.80952380952381\n",
            "Accuracy using gini:  94.28571428571428\n",
            "depth =  10\n",
            "Accuracy using entropy:  93.80952380952381\n",
            "Accuracy using gini:  94.28571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWAN_wWXHMOQ"
      },
      "source": [
        "Gini is used to avoid xor problems where tree height should be exponentially higher for getting purity.<br>\n",
        "We are test depths to see which gives better accuracy which we got a 6 and then constant for the further increase.<br>\n",
        "2. What is boosting, bagging and  stacking?\n",
        "Which class does random forests belong to and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnO5uqHlHMOR"
      },
      "source": [
        "Answer:<br>\n",
        "1)Boosting: Prediction made be a model is given as input to next layer model one by one(sequential).<br>\n",
        "2)Bagging: Averaging or voting the predictions made by different models independently.<br>\n",
        "3)Stacking: Each individual models prediction is stacked and used as input to the final estimator to predict.<br>\n",
        "\n",
        "Random Forests belong to bagging because in random forests multiple decision tree models predict the outcome and then they will be voted(averaging) for final prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihvGbqLHMOS"
      },
      "source": [
        "3. Implement random forest algorithm using different decision trees . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXdPP2aIHMOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8cc86f6-1d94-433b-e780-13210f0c66ce"
      },
      "source": [
        "def trainModel(X_train, y_train, criterion, max_depth, min_samples_leaf, max_features):\n",
        "    clf_gini = DecisionTreeClassifier(criterion = criterion, random_state = 100, max_depth=max_depth, min_samples_leaf=min_samples_leaf, max_features=max_features)\n",
        "    clf_gini.fit(X_train, y_train)\n",
        "    return clf_gini\n",
        "\n",
        "numTrees = 5\n",
        "max_depth=3\n",
        "min_samples_leaf=5\n",
        "max_features=3\n",
        "criterion = 'gini' #use 'entropy' for entropy criterion\n",
        "\n",
        "all_predictions = []\n",
        "X_train, real_X_test, y_train, real_y_test = train_test_split( X, Y, test_size = 0.3)\n",
        "for i in range(0, numTrees):\n",
        "    X_train, X_test, y_train, y_test = train_test_split( X, Y, train_size = 0.7, random_state=100)\n",
        "    modelRand = trainModel(X_train, y_train, criterion, max_depth, min_samples_leaf, max_features)\n",
        "    y_gini = modelRand.predict(real_X_test)\n",
        "    all_predictions.append(y_gini)\n",
        "\n",
        "\n",
        "ap_transpose = l2 =[[row[i] for row in all_predictions] for i in range(len(all_predictions[0]))]\n",
        "y_rand = [max(row) for row in ap_transpose]\n",
        "print(\"Accuracy using random trees: \", accuracy_score(real_y_test,y_rand)*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using random trees:  96.19047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJOn5nNZHMOU"
      },
      "source": [
        "4. Report the accuracies obtained after using the Random forest algorithm and compare it with the best accuracies obtained with the decision trees. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vwbAE0tfEmw"
      },
      "source": [
        "Best accuracy from decision tree is 94.28571428571428 at depth 6, using gini.<br>\n",
        "By using random forests we are getting accuracy in a range of 93 to 96 which is performing a bit better than decision tree alone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj-vNvsYHMOX"
      },
      "source": [
        "5. Submit your solution as a separate pdf in the final zip file of your submission\n",
        "\n",
        "\n",
        "Compute a decision tree with the goal to predict the food review based on its smell, taste and portion size.\n",
        "\n",
        "(a) Compute the entropy of each rule in the first stage.\n",
        "\n",
        "(b) Show the final decision tree. Clearly draw it.\n",
        "\n",
        "Submit a handwritten response. Clearly show all the steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIovQ87uXOxd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}